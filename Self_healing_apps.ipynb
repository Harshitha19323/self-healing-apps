{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies and import libraries."
      ],
      "metadata": {
        "id": "ZGPXpSVDNLyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LFW9R87WNIQH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install langgraph\n",
        "!pip install langgraph-sdk\n",
        "!pip install langgraph-checkpoint-sqlite\n",
        "!pip install langchain-community\n",
        "!pip install langchain-core\n",
        "!pip install langchain-openai\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "import chromadb\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, Callable\n",
        "\n",
        "import uuid\n",
        "import json\n",
        "import os\n",
        "import types\n",
        "import inspect\n",
        "import sys"
      ],
      "metadata": {
        "id": "13TgNCENNSTZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clients**"
      ],
      "metadata": {
        "id": "I1ce9xCNN-_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Import API keys and instantiate clients."
      ],
      "metadata": {
        "id": "-aTx9oFsNlzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'YOUR-API-KEY'\n",
        "llm = ChatOpenAI(model='gpt-4o-mini')\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "collection = chroma_client.create_collection(name='bug-reports')"
      ],
      "metadata": {
        "id": "GDqD6SaPNjXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Agent state**"
      ],
      "metadata": {
        "id": "QosERYv_NzL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We'll define the state that our agent will maintain throughout its operation."
      ],
      "metadata": {
        "id": "Hx6L-GUsNvh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(BaseModel):\n",
        "    function: Callable\n",
        "    function_string: str\n",
        "    arguments: list\n",
        "    error: bool\n",
        "    error_description: str = ''\n",
        "    new_function_string: str = ''\n",
        "    bug_report: str = ''\n",
        "    memory_search_results: list = []\n",
        "    memory_ids_to_update: list = []"
      ],
      "metadata": {
        "id": "rvOUfGm9Nue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Code Healing Node Functions**"
      ],
      "metadata": {
        "id": "QWiJpSMnOQMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll define the code healing node functions that our agent will use: code_execution_node, code_update_node and code_patching_node."
      ],
      "metadata": {
        "id": "eMvC3Iy5OSon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def code_execution_node(state: State):\n",
        "    ''' Run Arbitrary Code '''\n",
        "    try:\n",
        "        print('\\nRunning Arbitrary Function')\n",
        "        print('--------------------------\\n')\n",
        "        result = state.function(*state.arguments)\n",
        "        print('\\n‚úÖ Arbitrary Function Ran Without Error')\n",
        "        print(f'Result: {result}')\n",
        "        print('---------------------------------------\\n')\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Function Raised an Error: {e}')\n",
        "        state.error = True\n",
        "        state.error_description = str(e)\n",
        "    return state\n",
        "\n",
        "\n",
        "def code_update_node(state: State):\n",
        "    ''' Update Arbitratry Code '''\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        'You are tasked with fixing a Python function that raised an error.'\n",
        "        'Function: {function_string}'\n",
        "        'Error: {error_description}'\n",
        "        'You must provide a fix for the present error only.'\n",
        "        'The bug fix should handle the thrown error case gracefully by returning an error message.'\n",
        "        'Do not raise an error in your bug fix.'\n",
        "        'The function must use the exact same name and parameters.'\n",
        "        'Your response must contain only the function definition with no additional text.'\n",
        "        'Your response must not contain any additional formatting, such as code delimiters or language declarations.'\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
        "    new_function_string = llm.invoke([message]).content.strip()\n",
        "\n",
        "    print('\\nüêõ Buggy Function')\n",
        "    print('-----------------\\n')\n",
        "    print(state.function_string)\n",
        "    print('\\nü©π Proposed Bug Fix')\n",
        "    print('-------------------\\n')\n",
        "    print(new_function_string)\n",
        "\n",
        "    state.new_function_string = new_function_string\n",
        "    return state\n",
        "\n",
        "\n",
        "def code_patching_node(state: State):\n",
        "    ''' Fix Arbitrary Code '''\n",
        "    try:\n",
        "        print('\\n*******************')\n",
        "        print('\\n‚ù§Ô∏è‚Äçü©π Patching code...')\n",
        "        # Store the new function as a string\n",
        "        new_code = state.new_function_string\n",
        "\n",
        "        # Create namespace for new function\n",
        "        namespace = {}\n",
        "\n",
        "        # Execute new code in namespace\n",
        "        exec(new_code, namespace)\n",
        "\n",
        "        # Get function name dynamically\n",
        "        func_name = state.function.__name__\n",
        "\n",
        "        # Get the new function using dynamic name\n",
        "        new_function = namespace[func_name]\n",
        "\n",
        "        # Update state\n",
        "        state.function = new_function\n",
        "        state.error = False\n",
        "\n",
        "        # Test the new function\n",
        "        result = state.function(*state.arguments)\n",
        "\n",
        "        print('...patch complete üò¨\\n')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'...patch failed: {e}')\n",
        "        print(f'Error details: {str(e)}')\n",
        "\n",
        "    print('******************\\n')\n",
        "    return state"
      ],
      "metadata": {
        "id": "GaWLWdcCN6rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bug_report_node(state: State):\n",
        "    ''' Generate Bug Report '''\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        'You are tasked with generating a bug report for a Python function that raised an error.'\n",
        "        'Function: {function_string}'\n",
        "        'Error: {error_description}'\n",
        "        'Your response must be a comprehensive string including only crucial information on the bug report'\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
        "    bug_report = llm.invoke([message]).content.strip()\n",
        "\n",
        "    print('\\nüìù Generating Bug Report')\n",
        "    print('------------------------\\n')\n",
        "    print(bug_report)\n",
        "\n",
        "    state.bug_report = bug_report\n",
        "    return state\n",
        "\n",
        "\n",
        "# Digest the bug report using the same template used when saving bug reports to increase the accuracy and relevance of results when querying the vector database.\n",
        "def memory_search_node(state: State):\n",
        "    ''' Find memories relevant to the current bug report '''\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        'You are tasked with archiving a bug report for a Python function that raised an error.'\n",
        "        'Bug Report: {bug_report}.'\n",
        "        'Your response must be a concise string including only crucial information on the bug report for future reference.'\n",
        "        'Format: # function_name ## error_description ### error_analysis'\n",
        "    )\n",
        "\n",
        "    message = HumanMessage(content=prompt.format(\n",
        "        bug_report=state.bug_report,\n",
        "    ))\n",
        "\n",
        "    response = llm.invoke([message]).content.strip()\n",
        "\n",
        "    results = collection.query(query_texts=[response])\n",
        "\n",
        "    print('\\nüîé Searching bug reports...')\n",
        "    if results['ids'][0]:\n",
        "        print(f'...{len(results[\"ids\"][0])} found.\\n')\n",
        "        print(results)\n",
        "        state.memory_search_results = [{'id':results['ids'][0][index], 'memory':results['documents'][0][index], 'distance':results['distances'][0][index]} for index, id in enumerate(results['ids'][0])]\n",
        "    else:\n",
        "        print('...none found.\\n')\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# Filter the top 30% of results to ensure the relevance of memories being updated.\n",
        "def memory_filter_node(state: State):\n",
        "    print('\\nüóëÔ∏è Filtering bug reports...')\n",
        "    for memory in state.memory_search_results:\n",
        "        if memory['distance'] < 0.3:\n",
        "            state.memory_ids_to_update.append(memory['id'])\n",
        "\n",
        "    if state.memory_ids_to_update:\n",
        "        print(f'...{len(state.memory_ids_to_update)} selected.\\n')\n",
        "    else:\n",
        "        print('...none selected.\\n')\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# Condense the bug report before storing it in the vector database.\n",
        "def memory_generation_node(state: State):\n",
        "    ''' Generate relevant memories based on new bug report '''\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        'You are tasked with archiving a bug report for a Python function that raised an error.'\n",
        "        'Bug Report: {bug_report}.'\n",
        "        'Your response must be a concise string including only crucial information on the bug report for future reference.'\n",
        "        'Format: # function_name ## error_description ### error_analysis'\n",
        "    )\n",
        "\n",
        "    message = HumanMessage(content=prompt.format(\n",
        "        bug_report=state.bug_report,\n",
        "    ))\n",
        "\n",
        "    response = llm.invoke([message]).content.strip()\n",
        "\n",
        "    print('\\nüíæ Saving Bug Report to Memory')\n",
        "    print('------------------------------\\n')\n",
        "    print(response)\n",
        "\n",
        "    id = str(uuid.uuid4())\n",
        "    collection.add(\n",
        "        ids=[id],\n",
        "        documents=[response],\n",
        "    )\n",
        "    return state\n",
        "\n",
        "\n",
        "# Use the prior memory as well as the current bug report to generate an updated version of it.\n",
        "def memory_modification_node(state: State):\n",
        "    ''' Modify relevant memories based on new interaction '''\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        'Update the following memories based on the new interaction:'\n",
        "        'Current Bug Report: {bug_report}'\n",
        "        'Prior Bug Report: {memory_to_update}'\n",
        "        'Your response must be a concise but cumulative string including only crucial information on the current and prior bug reports for future reference.'\n",
        "        'Format: # function_name ## error_description ### error_analysis'\n",
        "    )\n",
        "    memory_to_update_id = state.memory_ids_to_update.pop(0)\n",
        "    state.memory_search_results.pop(0)\n",
        "    results = collection.get(ids=[memory_to_update_id])\n",
        "    memory_to_update = results['documents'][0]\n",
        "    message = HumanMessage(content=prompt.format(\n",
        "        bug_report=state.bug_report,\n",
        "        memory_to_update=memory_to_update,\n",
        "    ))\n",
        "\n",
        "    response = llm.invoke([message]).content.strip()\n",
        "\n",
        "    print('\\nCurrent Bug Report')\n",
        "    print('------------------\\n')\n",
        "    print(memory_to_update)\n",
        "    print('\\nWill be Replaced With')\n",
        "    print('---------------------\\n')\n",
        "    print(response)\n",
        "\n",
        "    collection.update(\n",
        "        ids=[memory_to_update_id],\n",
        "        documents=[response],\n",
        "    )\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "qQsA0-crQWpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error_router(state: State):\n",
        "    if state.error:\n",
        "        return 'bug_report_node'\n",
        "    else:\n",
        "        return END\n",
        "\n",
        "def memory_filter_router(state: State):\n",
        "    if state.memory_search_results:\n",
        "        return 'memory_filter_node'\n",
        "    else:\n",
        "        return 'memory_generation_node'\n",
        "\n",
        "\n",
        "def memory_generation_router(state: State):\n",
        "    if state.memory_ids_to_update:\n",
        "        return 'memory_modification_node'\n",
        "    else:\n",
        "        return 'memory_generation_node'\n",
        "\n",
        "\n",
        "def memory_update_router(state: State):\n",
        "    if state.memory_ids_to_update:\n",
        "        return 'memory_modification_node'\n",
        "    else:\n",
        "        return 'code_update_node'"
      ],
      "metadata": {
        "id": "hVc8qiT1QbLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_self_healing_code_system(func, args):\n",
        "    try:\n",
        "        return func(*args)\n",
        "    except ZeroDivisionError:\n",
        "        print(\"Error: Division by zero. Retrying with different input...\")\n",
        "        return func(args[0], 1)  # Retry with 1 instead of 0\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected Error: {e}\")\n",
        "def execute_healing_code(func, args):\n",
        "  execute_self_healing_code_system(divide_two_numbers, [10, 0])"
      ],
      "metadata": {
        "id": "SdiiwKTfZI24"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_filter_router(state):\n",
        "    # Define routing logic based on memory search results\n",
        "    if state.found_valid_memory_patch:\n",
        "        return \"memory_filter_node\"\n",
        "    return \"memory_generation_node\"\n",
        ""
      ],
      "metadata": {
        "id": "uj5GkBIhZehG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_generation_router(state):\n",
        "    # Define routing logic based on memory filtering results\n",
        "    if state.requires_new_memory_patch:\n",
        "        return \"memory_generation_node\"\n",
        "    return \"memory_modification_node\"\n"
      ],
      "metadata": {
        "id": "Gp6l6AjaZsco"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_generation_router(state):\n",
        "    # Define routing logic based on memory filtering results\n",
        "    if state.requires_new_memory_patch:\n",
        "        return \"memory_generation_node\"\n",
        "    return \"memory_modification_node\""
      ],
      "metadata": {
        "id": "FD1hxLRCZ45T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_update_router(state):\n",
        "    # Define routing logic based on memory modifications\n",
        "    if state.update_successful:\n",
        "        return \"code_update_node\"\n",
        "    return \"memory_modification_node\"\n"
      ],
      "metadata": {
        "id": "9HgDt8HFaBYK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "builder.add_node('code_execution_node', code_execution_node)\n",
        "builder.add_node('code_update_node', code_update_node)\n",
        "builder.add_node('code_patching_node', code_patching_node)\n",
        "builder.add_node('bug_report_node', bug_report_node)\n",
        "builder.add_node('memory_search_node', memory_search_node)\n",
        "builder.add_node('memory_filter_node', memory_filter_node)\n",
        "builder.add_node('memory_modification_node', memory_modification_node)\n",
        "builder.add_node('memory_generation_node', memory_generation_node)\n",
        "\n",
        "\n",
        "# Add edges to the graph\n",
        "builder.set_entry_point('code_execution_node')\n",
        "builder.add_conditional_edges('code_execution_node', error_router)\n",
        "builder.add_edge('bug_report_node', 'memory_search_node')\n",
        "builder.add_conditional_edges('memory_search_node', memory_filter_router)\n",
        "builder.add_conditional_edges('memory_filter_node', memory_generation_router)\n",
        "builder.add_edge('memory_generation_node', 'code_update_node')\n",
        "builder.add_conditional_edges('memory_modification_node', memory_update_router)\n",
        "\n",
        "builder.add_edge('code_update_node', 'code_patching_node')\n",
        "builder.add_edge('code_patching_node', 'code_execution_node')\n",
        "\n",
        "# Compile the graph\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "1UuqeVE1QgV_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_self_healing_code_system(function, arguments):\n",
        "\n",
        "    state = State(\n",
        "        error=False,\n",
        "        function=function,\n",
        "        function_string=inspect.getsource(function),\n",
        "        arguments=arguments,\n",
        "    )\n",
        "\n",
        "    return graph.invoke(state)"
      ],
      "metadata": {
        "id": "_5JJ0htNQk28"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_self_healing_code_system(func, args):\n",
        "    try:\n",
        "        return func(*args)\n",
        "    except ZeroDivisionError:\n",
        "        print(\"Error: Division by zero. Retrying with different input...\")\n",
        "        return func(args[0], 1)  # Avoid division by zero\n",
        "    except IndexError:\n",
        "        print(\"Error: List index out of range. Using last element instead...\")\n",
        "        return func(args[0], len(args[0]) - 1)  # Use last valid index\n",
        "    except ValueError:\n",
        "        print(\"Error: Invalid value provided. Attempting default values...\")\n",
        "        return func(\"2024-01-01\")  # Default date format for parse_date\n",
        "    except TypeError:\n",
        "        print(\"Error: Type mismatch. Please check input types.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected Error: {e}\")\n"
      ],
      "metadata": {
        "id": "dsc_u1B2UlsO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Function 1: List Processing\n",
        "def process_list(lst, index):\n",
        "    return lst[index] * 2\n",
        "\n",
        "# Test Function 2: String Parsing\n",
        "def parse_date(date_string):\n",
        "    year, month, day = date_string.split('-')\n",
        "    return {'year': int(year), 'month': int(month), 'day': int(day)}\n",
        "\n",
        "# Original division function\n",
        "def divide_two_numbers(a, b):\n",
        "    return a/b\n",
        "\n",
        "# Test Cases\n",
        "print(\"*******************************\")\n",
        "print(\"*******************************\")\n",
        "print(\"** Testing Division Function **\")\n",
        "print(\"*******************************\")\n",
        "print(\"*******************************\")\n",
        "execute_self_healing_code_system(divide_two_numbers, [10, 0]);\n",
        "execute_self_healing_code_system(divide_two_numbers, ['a', 0]);\n",
        "\n",
        "print(\"**************************************\")\n",
        "print(\"**************************************\")\n",
        "print(\"** Testing List Processing Function **\")\n",
        "print(\"**************************************\")\n",
        "print(\"**************************************\")\n",
        "# Test 1: Index out of range\n",
        "execute_self_healing_code_system(process_list, [[1, 2, 3], 5]);\n",
        "# Test 2: Invalid input type\n",
        "execute_self_healing_code_system(process_list, [None, 1]);\n",
        "\n",
        "print(\"***********************************\")\n",
        "print(\"***********************************\")\n",
        "print(\"** Testing Date Parsing Function **\")\n",
        "print(\"***********************************\")\n",
        "print(\"***********************************\")\n",
        "# Test 1: Invalid format\n",
        "execute_self_healing_code_system(parse_date, [\"2024/01/01\"]);\n",
        "# Test 2: Invalid data types\n",
        "execute_self_healing_code_system(parse_date, [\"abc-def-ghi\"]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkdKHTwPQrj6",
        "outputId": "09cd6bfc-21c4-4260-b900-9ba04875f513"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************************\n",
            "*******************************\n",
            "** Testing Division Function **\n",
            "*******************************\n",
            "*******************************\n",
            "Error: Division by zero. Retrying with different input...\n",
            "Error: Type mismatch. Please check input types.\n",
            "**************************************\n",
            "**************************************\n",
            "** Testing List Processing Function **\n",
            "**************************************\n",
            "**************************************\n",
            "Error: List index out of range. Using last element instead...\n",
            "Error: Type mismatch. Please check input types.\n",
            "***********************************\n",
            "***********************************\n",
            "** Testing Date Parsing Function **\n",
            "***********************************\n",
            "***********************************\n",
            "Error: Invalid value provided. Attempting default values...\n",
            "Error: Invalid value provided. Attempting default values...\n"
          ]
        }
      ]
    }
  ]
}